import mlflow
import numpy as np
import pandas as pd
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
import joblib
import os
from datetime import datetime

def classification_metrics(y_true, y_pred, prefix=""):
    """–†–∞—Å—á–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—Ç –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    metrics = {
        f"{prefix}accuracy": accuracy_score(y_true, y_pred),
        f"{prefix}f1_macro": f1_score(y_true, y_pred, average="macro"),
        f"{prefix}precision_macro": precision_score(y_true, y_pred, average="macro"),
        f"{prefix}recall_macro": recall_score(y_true, y_pred, average="macro")
    }
    return metrics

def train_and_evaluate_models(X_train, X_test, y_train, y_test, feature_names):
    """–û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ MLflow"""
    print("üìà –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
    
    models = {
        "LogisticRegression": make_pipeline(LogisticRegression(solver="liblinear", random_state=42, max_iter=1000)),
        "SVC": make_pipeline(SVC(gamma="auto", random_state=42, probability=True)),
        "KNN": make_pipeline(KNeighborsClassifier(n_neighbors=15)),
        "DecisionTree": make_pipeline(DecisionTreeClassifier(max_depth=7, random_state=42)),
        "RandomForest": make_pipeline(RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),
        "GradientBoosting": make_pipeline(GradientBoostingClassifier(random_state=42))
    }
    
    best_f1 = 0
    best_model_info = {}
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –º–æ–¥–µ–ª–µ–π
    os.makedirs("models", exist_ok=True)
    
    for model_name, model in models.items():
        print(f"\n{'-' * 50}")
        print(f"üîç –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
        
        with mlflow.start_run(run_name=f"{model_name}_{timestamp}") as run:
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            mlflow.log_param("model_type", model_name)
            mlflow.log_param("random_state", 42)
            mlflow.log_param("timestamp", timestamp)
            
            # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π
            if model_name == "KNN":
                mlflow.log_param("n_neighbors", 15)
            elif model_name == "DecisionTree":
                mlflow.log_param("max_depth", 7)
            elif model_name == "RandomForest":
                mlflow.log_param("n_estimators", 100)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            print("   ‚è≥ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            model.fit(X_train, y_train)
            print("   ‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            train_metrics = classification_metrics(y_train, y_train_pred, "train_")
            test_metrics = classification_metrics(y_test, y_test_pred, "test_")
            
            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            print("   ‚è≥ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
            cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')
            cv_mean = np.mean(cv_scores)
            cv_std = np.std(cv_scores)
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            for metric_name, value in {**train_metrics, **test_metrics}.items():
                mlflow.log_metric(metric_name, value)
            
            mlflow.log_metric("cv_f1_mean", float(cv_mean))
            mlflow.log_metric("cv_f1_std", float(cv_std))
            
            # –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –≤ –∫–æ–Ω—Å–æ–ª—å
            print(f"   üìä –ú–µ—Ç—Ä–∏–∫–∏ (test):")
            print(f"      ‚Ä¢ Accuracy: {test_metrics['test_accuracy']:.4f}")
            print(f"      ‚Ä¢ F1-score (macro): {test_metrics['test_f1_macro']:.4f}")
            print(f"      ‚Ä¢ Precision (macro): {test_metrics['test_precision_macro']:.4f}")
            print(f"      ‚Ä¢ Recall (macro): {test_metrics['test_recall_macro']:.4f}")
            print(f"   üîÑ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è F1: {cv_mean:.4f} ¬± {cv_std:.4f}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path = f"models/{model_name}_{timestamp}.pkl"
            joblib.dump(model, model_path)
            mlflow.log_artifact(model_path)
            print(f"   üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if test_metrics["test_f1_macro"] > best_f1:
                best_f1 = test_metrics["test_f1_macro"]
                best_model_info = {
                    "model_name": model_name,
                    "best_f1": best_f1,
                    "model": model,
                    "run_id": run.info.run_id,
                    "model_path": model_path
                }
            
            print(f"   ‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {model_name}")
    
    print(f"\n{'=' * 50}")
    print("üèÜ –ò–¢–û–ì–ò –û–ë–£–ß–ï–ù–ò–Ø:")
    print(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_info['model_name']}")
    print(f"–õ—É—á—à–∏–π F1-score (test): {best_model_info['best_f1']:.4f}")
    print(f"ID –∑–∞–ø—É—Å–∫–∞ MLflow: {best_model_info['run_id']}")
    print(f"–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏: {best_model_info['model_path']}")
    
    return best_model_info